{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EF1p3_CIFAR10.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPzpR4pZ6veToGv5NWqrHQN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SamuelBFG/DL-studies/blob/master/IA353/EF1p3_CIFAR10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owyXiY8qcuEo"
      },
      "source": [
        "# Base Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bga7q8icArd"
      },
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.optimizers import Adam"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ackUko9cjh_"
      },
      "source": [
        "cifar10 = tf.keras.datasets.cifar10\n",
        "(x_train, y_train),(x_test, y_test) = cifar10.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJebBcjuckxC",
        "outputId": "c04e1654-21ec-4ed3-b3cf-595010f6dd3a"
      },
      "source": [
        "print('x_train shape:', x_train.shape)\n",
        "print('x_test shape:', x_test.shape)\n",
        "print('y_train shape:', y_train.shape)\n",
        "print('y_test shape:', y_test.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (50000, 32, 32, 3)\n",
            "x_test shape: (10000, 32, 32, 3)\n",
            "y_train shape: (50000, 1)\n",
            "y_test shape: (10000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6iuAGO3PcmGp",
        "outputId": "6dd0c5b1-fd22-499f-826f-0e02a0304965"
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        " tf.keras.layers.Flatten(),\n",
        " tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
        " tf.keras.layers.Dropout(0.5),\n",
        " tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "])\n",
        "\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        " loss='sparse_categorical_crossentropy',\n",
        " metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_train, y_train, epochs=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1563/1563 [==============================] - 18s 11ms/step - loss: 2.2434 - accuracy: 0.1866\n",
            "Epoch 2/5\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 2.0392 - accuracy: 0.2263\n",
            "Epoch 3/5\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 2.0174 - accuracy: 0.2402\n",
            "Epoch 4/5\n",
            " 907/1563 [================>.............] - ETA: 7s - loss: 2.0019 - accuracy: 0.2524"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bf1eTbfFdVFK"
      },
      "source": [
        "## Test Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5kkkwMacn2f"
      },
      "source": [
        "model.evaluate(x_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDWpPEnactC_"
      },
      "source": [
        "## Working with multiple executions to stabilize results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bw0zhsRVdWu9"
      },
      "source": [
        "executions = 5\n",
        "histories = []\n",
        "evaluations = []\n",
        "\n",
        "for i in range(executions):\n",
        "  model = tf.keras.models.Sequential([\n",
        "                                      tf.keras.layers.Flatten(),\n",
        "                                      tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
        "                                      tf.keras.layers.Dropout(0.5),\n",
        "                                      tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "                                      ])\n",
        "  \n",
        "  print('## Training model number: ', i+1)\n",
        "\n",
        "  model.compile(optimizer='adam',\n",
        "                      loss='sparse_categorical_crossentropy',\n",
        "                      metrics=['accuracy'])\n",
        "  \n",
        "  histories.append(model.fit(x_train, y_train, epochs=5, verbose=0))\n",
        "\n",
        "  print('#â€¢ Test set:')\n",
        "  evaluations.append(model.evaluate(x_test, y_test))\n",
        "  print('\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_L7N0NAdZhd"
      },
      "source": [
        "histories[0].history.keys()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jpGeo8BAfhgK"
      },
      "source": [
        "plt.figure(figsize=(8, 6))  \n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('Error')\n",
        "plt.title('Training Loss')\n",
        "for i in range(executions):\n",
        "  plt.plot(histories[i].history['loss'])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqfncKzWfiJ3"
      },
      "source": [
        "histories[-1].history['accuracy'] # Last training acc log per epochs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pcsyAqH7fj82"
      },
      "source": [
        "evaluations[0] # Loss and acc for the first model (LIST)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_AnI_EZUfkiU"
      },
      "source": [
        "acc_val = []\n",
        "acc_test = []\n",
        "\n",
        "for i in range(executions):\n",
        "  acc_val.append(sum(histories[i].history['accuracy']) / len(histories[i].history['accuracy']))\n",
        "  acc_test.append(evaluations[i][1])\n",
        "\n",
        "acc_val"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JHHkTugMflFN"
      },
      "source": [
        "acc_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8I62TcFfnEc"
      },
      "source": [
        "### Average validation accuracy (training set)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2RyDTZOflzk"
      },
      "source": [
        "avg_acc_val = sum(acc_val)/len(acc_val)\n",
        "avg_acc_val"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0GNgC__fpIh"
      },
      "source": [
        "### Average test accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBM8wlD9fn7w"
      },
      "source": [
        "avg_acc_test = sum(acc_test)/len(acc_test)\n",
        "avg_acc_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GdNnjEQ6ft-9"
      },
      "source": [
        "## Kfold Cross-Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkWxJcCLfqGJ"
      },
      "source": [
        "cifar10 = tf.keras.datasets.cifar10\n",
        "(x_train, y_train),(x_test, y_test) = cifar10.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O81o3YwufwRR"
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Define per-fold score containers\n",
        "acc_per_fold = []\n",
        "loss_per_fold = []\n",
        "num_folds = 10\n",
        "\n",
        "\n",
        "train_data, train_data_val, train_labels, train_labels_val = train_test_split(x_train, y_train, test_size = 0.2)\n",
        "inputs = np.concatenate((train_data, train_data_val), axis=0)\n",
        "targets = np.concatenate((train_labels, train_labels_val), axis=0)\n",
        "\n",
        "kfold = KFold(n_splits=num_folds, shuffle=True)\n",
        "\n",
        "# K-fold Cross Validation model evaluation\n",
        "fold_no = 1\n",
        "\n",
        "for train, test in kfold.split(inputs, targets):\n",
        "  model = tf.keras.models.Sequential([\n",
        "                                      tf.keras.layers.Flatten(),\n",
        "                                      tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
        "                                      tf.keras.layers.Dropout(0.5),\n",
        "                                      tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "                                      ])\n",
        "  \n",
        "  model.compile(optimizer='adam',\n",
        "                loss='sparse_categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "  \n",
        "  history = model.fit(inputs[train], targets[train],\n",
        "              batch_size=64,\n",
        "              epochs=5,\n",
        "              verbose=0)\n",
        "\n",
        "  # Generate generalization metrics\n",
        "  scores = model.evaluate(x_test, y_test, verbose=0)\n",
        "  print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
        "  acc_per_fold.append(scores[1] * 100)\n",
        "  loss_per_fold.append(scores[0])\n",
        "\n",
        "  fold_no = fold_no + 1\n",
        "\n",
        "\n",
        "# == Provide average scores ==\n",
        "print('------------------------------------------------------------------------')\n",
        "print('Score per fold')\n",
        "for i in range(0, len(acc_per_fold)):\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\n",
        "print('------------------------------------------------------------------------')\n",
        "print('Average scores for all folds:')\n",
        "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
        "print(f'> Loss: {np.mean(loss_per_fold)}')\n",
        "print('------------------------------------------------------------------------')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2M5pSpl1iSk4"
      },
      "source": [
        "# Modified Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iabyF_xFf1p5"
      },
      "source": [
        "cifar10 = tf.keras.datasets.cifar10\n",
        "(x_train, y_train),(x_test, y_test) = cifar10.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJoAwtjNoI-G"
      },
      "source": [
        "#### 1024 neurons"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r30rhNzHiW8O"
      },
      "source": [
        "train_data, train_data_val, train_labels, train_labels_val = train_test_split(x_train, y_train, test_size = 0.2)\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        " tf.keras.layers.Flatten(),\n",
        " tf.keras.layers.Dense(1024, activation=tf.nn.relu),\n",
        " tf.keras.layers.Dropout(0.5),\n",
        "  # tf.keras.layers.Dense(256, activation=tf.nn.relu),  \n",
        "#  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
        " tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "])\n",
        "\n",
        "model.compile(optimizer = Adam(lr=0.001),\n",
        " loss='sparse_categorical_crossentropy',\n",
        " metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(train_data, train_labels, epochs=5, batch_size=64, validation_data = (train_data_val, train_labels_val), verbose = 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wElQoejGijSp"
      },
      "source": [
        "model.evaluate(x_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7GqWUpZi_AS"
      },
      "source": [
        "plt.figure(figsize=(8, 6))  \n",
        "plt.plot(history.history['loss'], color='b')\n",
        "plt.plot(history.history['val_loss'], color='r')\n",
        "plt.title('Loss')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('Error')\n",
        "plt.legend(('Training Loss', 'Validation Loss'))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u49DSwTkoRU-"
      },
      "source": [
        "#### 2 layers with 512 neurons"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hV416KZfi_q3"
      },
      "source": [
        "train_data, train_data_val, train_labels, train_labels_val = train_test_split(x_train, y_train, test_size = 0.2)\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        " tf.keras.layers.Flatten(),\n",
        " tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
        " tf.keras.layers.Dropout(0.5),\n",
        " tf.keras.layers.Dense(512, activation=tf.nn.relu),  \n",
        "#  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
        " tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "])\n",
        "\n",
        "model.compile(optimizer = Adam(lr=0.001),\n",
        " loss='sparse_categorical_crossentropy',\n",
        " metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(train_data, train_labels, epochs=5, batch_size=64, validation_data = (train_data_val, train_labels_val), verbose = 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WdPGV5QVn-PW"
      },
      "source": [
        "model.evaluate(x_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mCcvnton-y7"
      },
      "source": [
        "plt.figure(figsize=(8, 6))  \n",
        "plt.plot(history.history['loss'], color='b')\n",
        "plt.plot(history.history['val_loss'], color='r')\n",
        "plt.title('Loss')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('Error')\n",
        "plt.legend(('Training Loss', 'Validation Loss'))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TLd8htd6oMoK"
      },
      "source": [
        "#### 2 layers with 512 and 256 neurons "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPPHEc1nn_lU"
      },
      "source": [
        "train_data, train_data_val, train_labels, train_labels_val = train_test_split(x_train, y_train, test_size = 0.2)\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        " tf.keras.layers.Flatten(),\n",
        " tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
        " tf.keras.layers.Dropout(0.5),\n",
        " tf.keras.layers.Dense(256, activation=tf.nn.relu),  \n",
        "#  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
        " tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "])\n",
        "\n",
        "model.compile(optimizer = Adam(lr=0.001),\n",
        " loss='sparse_categorical_crossentropy',\n",
        " metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(train_data, train_labels, epochs=5, batch_size=64, validation_data = (train_data_val, train_labels_val), verbose = 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RyBnt70joBz2"
      },
      "source": [
        "model.evaluate(x_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSDe97vAoCXD"
      },
      "source": [
        "plt.figure(figsize=(8, 6))  \n",
        "plt.plot(history.history['loss'], color='b')\n",
        "plt.plot(history.history['val_loss'], color='r')\n",
        "plt.title('Loss')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('Error')\n",
        "plt.legend(('Training Loss', 'Validation Loss'))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}